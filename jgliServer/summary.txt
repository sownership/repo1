- 무조건적인 확장성보다는 변할 것과 변하지 않을 것을 잘 결정하는 것이 중요.

- 통신방식, 프로토콜, 요청처리방식, 처리로직들이 서로 의존성이 없도록 설계하여 결합도가 낮음
- systemin, socket 뿐 아니라 새로운 통신방식을 사용하는 서버도 지원하도록 설계
- 다양한 통신방식을 사용하는 클라이언트들을 동일하게 취급할 수 있도록 설계
- 통신방식이 같아도 다양한 프로토콜을 처리할 수 있도록 설계
- 인크립션 뿐 아니라 다른 형태의 요청도 처리할 수 있도록 함

- 파일/통신 입출력은 비동기로 설계하여 thread 자원 활용율을 높임
- 요청 command 에 따라 동적으로 의존성을 주입할 수 있도록 dependancyinjectionutil 을 사용함
  구현은 reflection 과 설정파일을 사용함
- 인크립션은 서로 결합해서 사용할 수 있음 즉, 서브클래싱을 피할 수 있는 구조로 되어 있음.
- 인크립션 방식이 다르다고 controller 가 추가되지 않도록 설계함.
  즉 하나의 controller 가 요청 명령에 따라 다양한 인크립터를 사용할 수 있음
- java nio.2 비동기 통신을 통해 적의수의 thread 로 많은 client 를 처리할 수 있다
- client 가 응답하지 않는 경우 timeout 처리를 하고 구현은 scheduledExecutorService 를 사용한다.
- controller 가 사용할 ThreadPool 은 cpu core 수 만큼만 사용한다.
  file, socket 처리가 모두 비동기이기 때문이다.
- 인크립터는 현재까지 읽은 파일에서 확실한 부분만 처리하고 나머지는 보관한다
- OOM 방지를 위해 파일은 한번에 8k 만큼만 읽는다.
	 * read -> Convert -> write 가 계속된다
	 * read 는 한번에 8k 이상하는 것은 더 이상의 성능향상이 없다. 오히려 메모리 부담을 줄 수 있다
	 * read 와 write 가 너무 느리므로 Convert 8k 를 multithread 로 하는 것은 전체 속도에 의미를 못준다
	 * 오히려 read 와 write 를 위한 thread 를 잡아두지 않는 것이 최선이다
	 * 즉 read 와 write 를 비동기로 처리한다
- 제안: 프로토콜 설계의 보완. 예를들어 인크립션방식 등이 client 로부터 전달.

https://www.concretepage.com/java/jdk7/example-seekablebytechannel-java-nio-channels



- 본 제품이 시장 경쟁력이 있으려면 성능이 좋고 확장성이 있어야 합니다.
그래서 이 두가지 관점에서 설계를 진행하였습니다.
첫째 성능은 1만개 클라이언트를 동시에 서비스할 정도로 설계하였습니다.
1만개로 목표한 이유는 c10k problem 으로도 잘 알려진 것처럼 단일노드에서
1만개 클라이언트를 동시에 서비스 하는 것이 그만큼 어려우므로 경쟁력이 있게 되는 부분입니다.
실제로 설계한 대로 모든 기능까지는 아니지만 구현을 해서 성능 검증을 해 보았는데
회사에서 지급받은 노트북으로 100k 즉 10만 클라이언트에 동시 서비스가 잘 되었습니다.
클라이언트들과는 2000-8000 tps 로 통신이 이루어졌습니다. 파일도 동시에 1k 파일ㅇ르 100k 오픈해서 처리합니다.
이때 총 사용된 thread 수는 8 개입니다.
즉 모든 i/o 및 biz logic 을 비동기로 작성한 것입니다.
잘 아시다시피 이는 적합한 기술과 알고리즘을 적용하는 것 뿐 아니라 많은 경험이 필요한 부분입니다.
예를 들어 물밀듯이 밀려들어오는 connect 요청들을 어떻게 최대한 refuse 하지 않고 받아낼 것인지
송수신, 압축, 파일처리의 cpu 비중을 어떻게 할 것인지, 10만 클라이언트에 대해 OOM 이 발생하지 않는
상태로 어떻게 최선의 퍼포먼스를 낼지 등등에 대한 것들일 것입니다.
시연하고 소스로 설명드리면 참 편한데.. 아쉽습니다.
둘째 확장성 부분에 대해 말씀 드리겠습니다.
확장성 있게 설계하기 위해 가장 중요한 부분은 변할 가능성이 있는 부분과 변할 가능성이 없는 부분을
명확하게 결정하는 것입니다. 모든 부분을 확장성 있게 설계하면 시스템의 복잡도가 너무 올라가게 되기 때문입니다.
저는 이 프로그램에서 변할 수 있는 부분을 통신방법, 데이터포맷, 명령어셋, 압축/인코딩 종류로 결정하였습니다.
그리고 이들을 OOP 5원칙에 따라 설계 및 구현하였습니다.
예를 들어 rs485 시리얼 통신 방식이 추가된다고 하면 이 시스템에서 변할 부분은 통신방법 모듈에
rs485 송수신 부분만 작성하고 나머지는 변하지 않습니다.
json 데이터 포맷이 추가된다면 decoder 만 하나 더 달아주면 됩니다.
파일 복사 command 가 추가된다면 copycontroller 만 추가해 주면 되겠습니다.
다른 예로 압축 방법이 추가된다면 그 압축을 수행하는 class 만 하나 구현하면 되겠습니다.
즉 open-closed 가 적용된 것입니다.

계속해서 적용한 기술에 대해 간단하게 살펴보겠습니다.
java nio.2 의 비동기 통신을 지원하는 class 들을 사용하였습니다.
대표적으로 asynchronousserversocketchannel 인데 이 accept, socket r/w 로 3개의 기능을 수행합니다.
client 입장에서 accept 를 빨리 처리 안해주면 exception 이 발생하므로 이 기능에 전체 쓰레드 8개 중 4개를
할당하였습니다.
또한 같은 이유로 accept 후 해야 할 일들은 이 4개가 아닌 biz threadpool 로 위임하였습니다.
biz threadpool 은 2개로 설정되어 있습니다. thread 가 2개밖에 없지만 모든 biz logic 도 비동기로
설계되어 초당 수천에서 수만개의 처리가 되는 것을 구현을 통해 확인하였습니다.
시간상 하위설계와 관련된 부분은 많이 적지 못했지만
여기서 bytebuffer 에 대해 dma 어로케이션을 사용하는 것 또한 중요합니다.
소켓 송수신과 뒤에 이야기할 파일입출력은 커널 메모리를 직접 사용해서 힙메모리 및 cpu 사용율을 절감할 수 있는
dma 어로케이션을 사용해야 합니다.
native code 와 관련된 메모리 사용이 없는 나머지 모듈들은 직접 힙메모리를 쓰는 것이 더 유리하겠습니다.

decoder 를 별도의 모듈로 둔 2가지 이유에 대해 말씀 드리겠습니다.
많은 클라이언트와 대량 통신을 하다보면 client 가 abc 라는 packet 을 전송해도
server 는 a 를 받고 잠시 후에 bc 를 받을 수 있습니다.
이렇게 연속으로 들어오는 byte들의 어디부터 어디까지가 의미있는 하나의 요청인지 디코딩을 해야 합니다.
만약 abc 중 ab 가 완결된 요청이고 c 는 다음 요청의 일부라면
decoder 는 ab 를 추출해서 돌려주고 c 는 가지고 있다가 다음 packet 과 연결해서 다시 decoding 을 하게 되는 것입니다.
두번째 이유는 data format 즉 data protocol 이 달라질 수 있기 때문에 확장성 측면에서 decode 모듈이 존재합니다.
예를 들어 json 기반의 protocol 도 있을 수 있고 xml 기반도 있을 수 있으며 이번 과제처럼 단순 word 기반의
data protocol 도 있을 수 있습니다. 즉 decoder 도 전략 패턴 형태로 사용되는 것입니다.
상황에 따라 디코더를 변경할 의도가 있으므로 전략패턴으로 볼 수 있고
억셉터에서 디코딩 추상층을 분리하려는 의도도 있으므로 브릿지 패턴을 적용했다고 볼 수도 있겠습니다.

accepter 에서 client packet 을 받아서 decoder 로 하여금 완성된 요청을 찾아내게 하고
그 결과를 controller 모듈로 보내서 biz 로직을 처리하도록 합니다.
controller 모듈은 전형적인 front controller 패턴을 사용하였습니다.
front controller 에서는 요청의 command 에 따라 적절한 처리 controller 로 요청을 전달하게 됩니다.
front controller 와 처리 controller 는 결합도를 낮추기 위해 dependancy inversion principle 이 적용되는데
이를 위해 외부 파일에 의한 의존성 주입하는 방법으로 설계하였습니다.
즉 command 에 매핑되는 controller 가 mapper 설정파일에 존재하게 됩니다.
또한 이 controller 들은 모두 single instance 로 동작합니다.
이유는 많은 클라이언트들이 동시에 많은 요청을 할 때마다 controller 를 생성하지 않기 위해서 입니다.
즉 cpu, memory 사용율을 낮추기 위함이고 이는 was 의 servlet 과 같은 구조라고 생각하시면 되겠습니다.
계속 관련된 내용을 말씀드리겠지만 이 설계는 회사 노트북에서 10000개의 클라이언트가 동시 요청을 했을 때
cpu, mem, thread 등에 문제가 발생하지 않도록 계산된 설계입니다.
또한 이 controller 구조 설계는 향후 이 프로그램이 압축,암호화뿐 아니라 다양한 요청을 처리하도록
열린 아키텍처입니다.

ack 를 처리하는 controller 는 commu controller 가 파일의 다음 내용을 처리하도록 신호를 전달해야 합니다.
이 프로그램에서는 모듈간 결합도를 낮추기 위해 전체적으로 eventbus pattern 즉 pub/sub 를 사용합니다.
commu controller 는 파일 8k 를 읽은 후 sub 후 client 로 전송하고 client 는 ack 를 보내면
ack controller 는 pub 를 하게되고 commu controller 가 다음 처리를 하게 됩니다.
이때 8kb 에 대해서도 이야기를 해 보겠습니다.
NTFS 나 linux 의 recommand block size 는 4KB 이고 효율을 위해 보통 8KB 를 사용한다.
8KB 이하는 8KB 보다 성능이 떨어지고 8KB 이상은 메모리 소비 대비 효율이 높지 않습니다.
그리고 동시 10만 클라이언트를 지원하기 위해 8KB 로 설계를 진행하였습니다.
AsynchronousFileChannel 로 비동기 io 를 하고 싶으나
jdk 의 windows 구현체의 경우는 file마다 thread 를 생성하는 문제가 있어서
seekablefilechannel 과 executorservice 를 이용해서 모든 요청이 공평하게 파일 처리가 되도록 한다.
이 때 file r/w 와 converter 에는 cpu core 의 1/4~1/2만 할당하여 시스템 전체 성능을 유지해 준다.

프로그램 플로우가 accept 후 socket read -> file read -> convert -> socket write 가 반복되는 구조인데


